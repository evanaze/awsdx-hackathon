{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e30e427b",
   "metadata": {},
   "source": [
    "# Geodata Manipulation\n",
    "\n",
    "EDA and data manipulation of GIS data using H3, Geopandas, and Shapely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f12b5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List\n",
    "\n",
    "import h3\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "461f1333",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m zipfile \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(datadir)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     40\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(datadir, zipfile)\n\u001b[0;32m---> 42\u001b[0m gdf \u001b[38;5;241m=\u001b[39m (\u001b[43mget_geodata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepare_districts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhex_fill_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m       )\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/pandas/core/generic.py:5839\u001b[0m, in \u001b[0;36mNDFrame.pipe\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5781\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   5782\u001b[0m \u001b[38;5;129m@doc\u001b[39m(klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpipe\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   5788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m   5789\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5790\u001b[0m \u001b[38;5;124;03m    Apply chainable functions that expect Series or DataFrames.\u001b[39;00m\n\u001b[1;32m   5791\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5837\u001b[0m \u001b[38;5;124;03m    ...  )  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m   5838\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5839\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/pandas/core/common.py:503\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(obj, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [12], line 36\u001b[0m, in \u001b[0;36mhex_fill_df\u001b[0;34m(gdf)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhex_fill_df\u001b[39m(gdf):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124;03m\"\"\"Fill the tracts with hexagons.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gdf\u001b[38;5;241m.\u001b[39massign(hex_fill \u001b[38;5;241m=\u001b[39m \u001b[43mgdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeom_swap_geojson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhex_fill_tract\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn [12], line 27\u001b[0m, in \u001b[0;36mhex_fill_tract\u001b[0;34m(geom_geojson, res, flag_swap)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"Fill a tract with small, res 13 hexagons.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m:param geom_geojson: The polygon to fill.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m:param res: The resolution to fill the polygons with.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m:param flag_swap: A flag indicating whether the polygon is geojson conformant or swapped.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     set_hexagons \u001b[38;5;241m=\u001b[39m \u001b[43mh3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolyfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeom_geojson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeo_json_conformant\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mflag_swap\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on data of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeom_geojson[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Continuing.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/h3/api/_api_template.py:424\u001b[0m, in \u001b[0;36m_API_FUNCTIONS.compact\u001b[0;34m(self, hexes)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03mCompact a collection of H3 cells by combining\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03msmaller cells into larger cells, if all child cells\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03munordered collection of H3Cell\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# todo: does compact work on mixed-resolution collections?\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m hu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_in_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m hc \u001b[38;5;241m=\u001b[39m _cy\u001b[38;5;241m.\u001b[39mcompact(hu)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_unordered(hc)\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/h3/api/basic_str/_binding.py:22\u001b[0m, in \u001b[0;36m_in_collection\u001b[0;34m(hexes)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_in_collection\u001b[39m(hexes):\n\u001b[0;32m---> 22\u001b[0m     it \u001b[38;5;241m=\u001b[39m [_cy\u001b[38;5;241m.\u001b[39mhex2int(h) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hexes]\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cy\u001b[38;5;241m.\u001b[39mfrom_iter(it)\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/h3/api/basic_str/_binding.py:22\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_in_collection\u001b[39m(hexes):\n\u001b[0;32m---> 22\u001b[0m     it \u001b[38;5;241m=\u001b[39m [\u001b[43m_cy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhex2int\u001b[49m(h) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hexes]\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cy\u001b[38;5;241m.\u001b[39mfrom_iter(it)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_geodata(filepath: str):\n",
    "    gdf = read_file(filepath)\n",
    "    return (gdf\n",
    "            .astype({\"INTPTLAT\": float, \"INTPTLON\": float, \"GEOID\": \"category\"})\n",
    "            .drop([\"STATEFP\", \"COUNTYFP\", \"TRACTCE\", \"ALAND\", \"AWATER\", \"NAME\", \n",
    "                   \"NAMELSAD\", \"MTFCC\", \"FUNCSTAT\"], axis=1)\n",
    "            .rename({\"INTPTLAT\": \"lat\", \"INTPTLON\": \"lon\", \"GEOID\": \"geoid\"}, axis=1)\n",
    "           )\n",
    "\n",
    "\n",
    "def prepare_districts(gdf_districts):\n",
    "    \"\"\"Loads a geojson files of polygon geometries and features,\n",
    "    swaps the latitude and longitude andstores geojson\"\"\"    \n",
    "    return (gdf_districts\n",
    "            .assign(geom_swap_geojson = lambda x: x[\"geometry\"].map(lambda polygon: transform(\n",
    "                       lambda x, y: (y, x), polygon)).apply(lambda y: mapping(y))))\n",
    "\n",
    "\n",
    "def hex_fill_tract(geom_geojson: dict, res: int = 13, flag_swap: bool = False) -> set:\n",
    "    \"\"\"Fill a tract with small, res 13 hexagons.\n",
    "\n",
    "    :param geom_geojson: The polygon to fill.\n",
    "    :param res: The resolution to fill the polygons with.\n",
    "    :param flag_swap: A flag indicating whether the polygon is geojson conformant or swapped.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        set_hexagons = h3.compact(h3.polyfill(geom_geojson, res, geo_json_conformant = flag_swap))\n",
    "    except ValueError:\n",
    "        print(f\"Error on data of type {geom_geojson['type']}. Continuing.\")\n",
    "        return set()\n",
    "    return list(set_hexagons)\n",
    "\n",
    "\n",
    "def hex_fill_df(gdf):\n",
    "    \"\"\"Fill the tracts with hexagons.\"\"\"\n",
    "    return gdf.assign(hex_fill = gdf[\"geom_swap_geojson\"].apply(hex_fill_tract))\n",
    "\n",
    "datadir = \"../data/zipfiles\"\n",
    "zipfile = os.listdir(datadir)[0]\n",
    "path = os.path.join(datadir, zipfile)\n",
    "\n",
    "gdf = (get_geodata(path)\n",
    "       .pipe(prepare_districts)\n",
    "       .pipe(hex_fill_df)\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26e11b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tracts = []\n",
    "\n",
    "for filename in os.listdir(\"../data/tract_polygons\"):\n",
    "    gdf = read_file(f\"../data/tract_polygons/{filename}/{filename}.shp\")\n",
    "    # Unify the CT boundries\n",
    "    union_poly = unary_union(gdf.geometry)\n",
    "    \n",
    "    # Convert to hexagon\n",
    "    temp  = mapping(g)\n",
    "    temp['coordinates']=[[[j[1],j[0]] for j in i] for i in temp['coordinates']]  \n",
    "    gdf['hexes'] = h3.polyfill(temp, APERTURE_SIZE)\n",
    "    all_tracts.append(gdf)\n",
    "    \n",
    "gdf = pd.concat(all_tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b74be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "APERTURE_SIZE = 3\n",
    "\n",
    "gdf = read_file(f\"../data/tract_polygons/tl_2020_01_tract/tl_2020_01_tract.shp\")\n",
    "union_poly = unary_union(gdf.geometry)\n",
    "temp  = mapping(union_poly)\n",
    "temp['coordinates']=[[[j[1],j[0]] for j in i] for i in temp['coordinates']]\n",
    "hexes = h3.polyfill(temp, APERTURE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "695166d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 07:50:36,456 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:50:41,455 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:50:41,557 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "2022-11-18 07:50:41,559 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "2022-11-18 07:50:46,456 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:50:51,456 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:50:56,456 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:51:01,457 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import h3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import mapping\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_geopandas import read_parquet\n",
    "\n",
    "from logging import getLogger\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "ZIP_DIR = os.path.join(DATA_DIR, \"zipfiles\")\n",
    "PARQUET_DIR = os.path.join(DATA_DIR, \"tract_parquet\")\n",
    "TILED_CENSUS_DIR = os.path.join(DATA_DIR, \"tiled_states\")\n",
    "\n",
    "LOGGER = getLogger(__name__)\n",
    "\n",
    "\n",
    "def prepare_districts(gdf):\n",
    "    \"\"\"Loads a geojson files of polygon geometries and features,\n",
    "    swaps the latitude and longitude and stores geojson\"\"\"\n",
    "    return gdf.assign(\n",
    "        geom_swap_geojson=lambda x: x[\"geometry\"]\n",
    "        .map(lambda polygon: transform(lambda x, y: (y, x), polygon))\n",
    "        .apply(lambda y: mapping(y))\n",
    "    )\n",
    "\n",
    "\n",
    "def hex_fill_tract(geom_geojson: dict, res: int = 13, flag_swap: bool = False) -> set:\n",
    "    \"\"\"Fill a tract with small, res 13 hexagons.\n",
    "\n",
    "    :param geom_geojson: The polygon to fill.\n",
    "    :param res: The resolution to fill the polygons with.\n",
    "    :param flag_swap: A flag indicating whether the polygon is geojson conformant or swapped.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        set_hexagons = h3.compact(\n",
    "            h3.polyfill(geom_geojson, res, geo_json_conformant=flag_swap)\n",
    "        )\n",
    "    except ValueError:\n",
    "        LOGGER.debug(\"Error on data of type %s. Continuing.\", geom_geojson[\"type\"])\n",
    "        return set()\n",
    "    return list(set_hexagons)\n",
    "\n",
    "\n",
    "def hex_fill_df(gdf):\n",
    "    \"\"\"Fill the tracts with hexagons.\"\"\"\n",
    "    return gdf.assign(hex_fill=gdf[\"geom_swap_geojson\"].apply(hex_fill_tract)).drop(\n",
    "        [\"geometry\", \"geom_swap_geojson\"], axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "def tile_partition(df: pd.DataFrame):\n",
    "    \"\"\"Tile a single tract.\"\"\"\n",
    "    return df.pipe(prepare_districts).pipe(hex_fill_df)\n",
    "\n",
    "\n",
    "cluster = LocalCluster(n_workers=8)\n",
    "# Get the list of files to read\n",
    "infiles = set(os.listdir(PARQUET_DIR))\n",
    "donefiles = set(os.listdir(TILED_CENSUS_DIR))\n",
    "files_todo = infiles.difference(donefiles)\n",
    "LOGGER.info(\"%s states to tile.\", len(files_todo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e981a900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 07:56:11,454 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:56:16,454 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:56:21,457 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:56:26,456 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:56:31,457 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:56:36,455 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Timed out trying to connect to tcp://127.0.0.1:57804 after 30 s",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCommClosedError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/comm/core.py:291\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(addr, timeout, deserialize, handshake_overrides, **connection_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     comm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait_for(\n\u001b[1;32m    292\u001b[0m         connector\u001b[38;5;241m.\u001b[39mconnect(loc, deserialize\u001b[38;5;241m=\u001b[39mdeserialize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconnection_args),\n\u001b[1;32m    293\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(intermediate_cap, time_left()),\n\u001b[1;32m    294\u001b[0m     )\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/asyncio/tasks.py:494\u001b[0m, in \u001b[0;36mwait_for\u001b[0;34m(fut, timeout, loop)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fut\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/comm/tcp.py:511\u001b[0m, in \u001b[0;36mBaseTCPConnector.connect\u001b[0;34m(self, address, deserialize, **connection_args)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m StreamClosedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;66;03m# The socket connect() call failed\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m     \u001b[43mconvert_stream_closed_error\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLCertVerificationError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/comm/tcp.py:142\u001b[0m, in \u001b[0;36mconvert_stream_closed_error\u001b[0;34m(obj, exc)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m FatalCommClosedError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CommClosedError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mCommClosedError\u001b[0m: in <distributed.comm.tcp.TCPConnector object at 0x7f83a47b9790>: ConnectionRefusedError: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 1\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py:988\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, address, loop, timeout, set_as_default, scheduler_file, security, asynchronous, name, heartbeat_interval, serializers, deserializers, extensions, direct_to_workers, connection_limit, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m preload_argv \u001b[38;5;241m=\u001b[39m dask\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistributed.client.preload-argv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreloads \u001b[38;5;241m=\u001b[39m preloading\u001b[38;5;241m.\u001b[39mprocess_preloads(\u001b[38;5;28mself\u001b[39m, preload, preload_argv)\n\u001b[0;32m--> 988\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m Client\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecreate_tasks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReplayTaskClient\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py:1185\u001b[0m, in \u001b[0;36mClient.start\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1185\u001b[0m     \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/utils.py:406\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[1;32m    405\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m error\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/utils.py:379\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    377\u001b[0m         future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(future, callback_timeout)\n\u001b[1;32m    378\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(future)\n\u001b[0;32m--> 379\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     error \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/tornado/gen.py:762\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 762\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py:1265\u001b[0m, in \u001b[0;36mClient._start\u001b[0;34m(self, timeout, **kwargs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler_comm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1265\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_connected(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close()\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py:1328\u001b[0m, in \u001b[0;36mClient._ensure_connected\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connecting_to_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1328\u001b[0m     comm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connect(\n\u001b[1;32m   1329\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39maddress, timeout\u001b[38;5;241m=\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection_args\n\u001b[1;32m   1330\u001b[0m     )\n\u001b[1;32m   1331\u001b[0m     comm\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClient->Scheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/comm/core.py:317\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(addr, timeout, deserialize, handshake_overrides, **connection_args)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(backoff)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimed out trying to connect to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    319\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mactive_exception\u001b[39;00m\n\u001b[1;32m    321\u001b[0m local_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomm\u001b[38;5;241m.\u001b[39mhandshake_info(),\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(handshake_overrides \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[1;32m    324\u001b[0m }\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;66;03m# This would be better, but connections leak if worker is closed quickly\u001b[39;00m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;66;03m# write, handshake = await asyncio.gather(comm.write(local_info), comm.read())\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: Timed out trying to connect to tcp://127.0.0.1:57804 after 30 s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 07:56:41,454 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:56:46,456 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:56:51,457 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:56:56,456 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:57:01,457 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:57:06,455 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:57:11,456 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:57:16,456 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:57:21,456 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 07:57:26,456 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:57:31,454 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:57:36,455 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:57:41,456 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n",
      "2022-11-18 07:57:46,456 - tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: 'tcp://127.0.0.1:39509' processes=2 threads=4, memory=7.77 GiB>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/compatibility.py\", line 161, in _run\n",
      "    val = self.callback()\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py\", line 1442, in _heartbeat\n",
      "    self.scheduler_comm.send({\"op\": \"heartbeat-client\"})\n",
      "  File \"/home/evan.azevedo/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/batched.py\", line 156, in send\n",
      "    raise CommClosedError(f\"Comm {self.comm!r} already closed.\")\n",
      "distributed.comm.core.CommClosedError: Comm <TCP (closed) Client->Scheduler local=tcp://127.0.0.1:57804 remote=tcp://127.0.0.1:39509> already closed.\n"
     ]
    }
   ],
   "source": [
    "client = Client(\"tcp://127.0.0.1:57804\")\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab9baf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 07:07:26,765 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-e8a0nuvr', purging\n",
      "2022-11-18 07:07:45,004 - distributed.worker_memory - WARNING - Worker tcp://127.0.0.1:33981 (pid=116672) exceeded 95% memory budget. Restarting...\n",
      "2022-11-18 07:07:45,141 - distributed.nanny - WARNING - Restarting worker\n",
      "2022-11-18 07:08:01,200 - distributed.worker_memory - WARNING - Worker tcp://127.0.0.1:42613 (pid=116852) exceeded 95% memory budget. Restarting...\n",
      "2022-11-18 07:08:01,347 - distributed.nanny - WARNING - Restarting worker\n",
      "2022-11-18 07:08:19,700 - distributed.worker_memory - WARNING - Worker tcp://127.0.0.1:43111 (pid=116892) exceeded 95% memory budget. Restarting...\n",
      "2022-11-18 07:08:19,827 - distributed.nanny - WARNING - Restarting worker\n",
      "2022-11-18 07:08:41,700 - distributed.worker_memory - WARNING - Worker tcp://127.0.0.1:46299 (pid=116942) exceeded 95% memory budget. Restarting...\n",
      "2022-11-18 07:08:41,918 - distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "KilledWorker",
     "evalue": "Attempted to run task ('to-parquet-09ec9af0e3eaf1addd9e01556a7caddc', 1) on 3 different workers, but all those workers died while running it. The last worker that attempt to run the task was tcp://127.0.0.1:46299. Inspecting worker logs is often a good next step to diagnose what went wrong. For more information see https://distributed.dask.org/en/stable/killed.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dd \u001b[38;5;241m=\u001b[39m \u001b[43mtile_geodata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [5], line 71\u001b[0m, in \u001b[0;36mtile_geodata\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m states to tile.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(files_todo))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Process the data in parallel using Dask\u001b[39;00m\n\u001b[1;32m     70\u001b[0m (\n\u001b[0;32m---> 71\u001b[0m     \u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPARQUET_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfiles_todo\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_partitions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtile_partition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeoid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCategoricalDtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhex_fill\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall_tiled_tracts.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/dask/dataframe/core.py:5274\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5271\u001b[0m \u001b[38;5;124;03m\"\"\"See dd.to_parquet docstring for more information\"\"\"\u001b[39;00m\n\u001b[1;32m   5272\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 5274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py:965\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, write_index, append, overwrite, ignore_divisions, partition_on, storage_options, custom_metadata, write_metadata_file, compute, compute_kwargs, schema, name_function, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m out \u001b[38;5;241m=\u001b[39m Scalar(graph, final_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[0;32m--> 965\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompute_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;66;03m# Invalidate the filesystem listing cache for the output path after write.\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;66;03m# We do this before returning, even if `compute=False`. This helps ensure\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;66;03m# that reading files that were just written succeeds.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m fs\u001b[38;5;241m.\u001b[39minvalidate_cache(path)\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/dask/base.py:315\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    dask.base.compute\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/dask/base.py:600\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    598\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 600\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py:3122\u001b[0m, in \u001b[0;36mClient.get\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   3120\u001b[0m         should_rejoin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3121\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3122\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3124\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py:2291\u001b[0m, in \u001b[0;36mClient.gather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2290\u001b[0m     local_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gather\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2294\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m    \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2298\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/utils.py:339\u001b[0m, in \u001b[0;36mSyncMethodMixin.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/utils.py:406\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[1;32m    405\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m error\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/utils.py:379\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    377\u001b[0m         future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(future, callback_timeout)\n\u001b[1;32m    378\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(future)\n\u001b[0;32m--> 379\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     error \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/tornado/gen.py:762\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 762\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/.pyenv/versions/awsdx-hackathon/lib/python3.8/site-packages/distributed/client.py:2154\u001b[0m, in \u001b[0;36mClient._gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   2152\u001b[0m         exc \u001b[38;5;241m=\u001b[39m CancelledError(key)\n\u001b[1;32m   2153\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2154\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[1;32m   2155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   2156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKilledWorker\u001b[0m: Attempted to run task ('to-parquet-09ec9af0e3eaf1addd9e01556a7caddc', 1) on 3 different workers, but all those workers died while running it. The last worker that attempt to run the task was tcp://127.0.0.1:46299. Inspecting worker logs is often a good next step to diagnose what went wrong. For more information see https://distributed.dask.org/en/stable/killed.html."
     ]
    }
   ],
   "source": [
    "# Process the data in parallel using Dask\n",
    "    (\n",
    "        read_parquet([os.path.join(PARQUET_DIR, file) for file in files_todo])\n",
    "        .map_partitions(\n",
    "            tile_partition,\n",
    "            meta={\n",
    "                \"geoid\": pd.CategoricalDtype,\n",
    "                \"lat\": np.float64,\n",
    "                \"lon\": np.float64,\n",
    "                \"hex_fill\": object,\n",
    "            },\n",
    "        )\n",
    "        .to_parquet(os.path.join(DATA_DIR, \"all_tiled_tracts.parquet\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379c451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awsdx-hackathon",
   "language": "python",
   "name": "awsdx-hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
